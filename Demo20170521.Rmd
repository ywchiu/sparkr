---
title: "Demo20170521"
author: "David Chiu"
date: "2017-5-21"
output: html_document
---

```{r}
if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
  Sys.setenv(SPARK_HOME = "/usr/local/spark")
}

library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))

sparkR.session(master = "spark://master:7077", 
               sparkConfig = list(spark.executor.memory = "600m"))

?read.df
lvr_prices <- read.csv("~/lvr_prices.csv")

lvr_data <- as.DataFrame(lvr_prices)

printSchema(lvr_data)
showDF(lvr_data)

head(lvr_prices[,c('area', 'total_price')])

a <- select(lvr_data, lvr_data$area, lvr_data$total_price)
head(a)

b <- filter(lvr_data, lvr_data$area == '大安區')
d <- select(b, b$area, b$total_price)
head(d)


head(filter(lvr_data, lvr_data$area == '大安區'))


?select

library(magrittr)

lvr_data %>%  SparkR::select(lvr_data$area, lvr_data$building_sqmeter, lvr_data$total_price) %>% 
   SparkR::filter(lvr_data$area == '大安區') %>% 
   SparkR::head()


```
## Aggregation
```{r}
##SELECT area, SUM(total_price) FROM lvr_data GROUP BY area;
head(summarize(groupBy(lvr_data, "area"), sumPrice = sum(lvr_data$total_price)))


##SELECT area, SUM(total_price) AS sumPrice FROM lvr_data GROUP BY area ORDER BY sumPrice DESC;
lvr_data %>%
  SparkR::groupBy("area") %>%
  SparkR::summarize(sumPrice = sum(lvr_data$total_price)) %>%
  SparkR::arrange(SparkR::desc(.$sumPrice)) %>%
  SparkR::head()



##SELECT area, AVF(total_price) AS mean_price FROM lvr_data GROUP BY area ORDER BY mean_price DESC;
lvr_data %>%
  SparkR::groupBy("area") %>%
  SparkR::summarize(mean_price = mean(lvr_data$total_price)) %>%
  SparkR::arrange(SparkR::desc(.$mean_price)) %>%
  SparkR::head()


house_price <- lvr_data %>%
  SparkR::groupBy("area") %>%
  SparkR::summarize(mean_price = mean(lvr_data$total_price)) %>%
  SparkR::arrange(SparkR::desc(.$mean_price)) %>%
  SparkR::collect()

barplot(height = house_price$mean_price, names.arg = house_price$area)

```
## Add Column
```{r}
lvr_data %>% head()

printSchema(lvr_data)


lvr_data$house_age <-  SparkR::datediff(SparkR::date_format(lvr_data$trading_ymd, 'yyyy-MM-dd'), SparkR::date_format(lvr_data$finish_ymd, 'yyyy-MM-dd')) / 365

lvr_data %>% head()


lvr_data$trading_ym <- date_format(lvr_data$trading_ymd, "yyyy-MM-01")
lvr_data %>% head()

## SELECT trading_ym, AVG(total_price) FROM lvr_data GROUP BY trading_ym;


house_prices <- lvr_data %>% 
  groupBy('trading_ym') %>%
  summarize(mean_price = mean(lvr_data$total_price)) %>%
  arrange(desc(.$mean_price)) %>%
  collect()

class(house_prices)
head(house_prices)
str(house_prices)

house_prices$trading_ym <- as.Date(house_prices$trading_ym)

#order(house_prices$trading_ym)
plot(mean_price[order(house_prices$trading_ym)] ~ trading_ym[order(house_prices$trading_ym)], data = house_prices, type='l')


house_prices2 <- lvr_data %>% 
  groupBy('trading_ym') %>%
  summarize(mean_price = mean(lvr_data$price_per_sqmeter)) %>%
  arrange(desc(.$mean_price)) %>%
  collect()

house_prices2$trading_ym <- as.Date(house_prices2$trading_ym)

#order(house_prices$trading_ym)
plot(mean_price[order(house_prices2$trading_ym)] ~ trading_ym[order(house_prices2$trading_ym)], data = house_prices2, type='l')


## SELECT area, trading_ym, AVG(total_price) FROM lvr_data GROUP BY trading_ym area;

house_prices3 <- lvr_data %>% 
  groupBy('area','trading_ym') %>%
  summarize(mean_price = mean(lvr_data$total_price)) %>%
  arrange(desc(.$mean_price)) %>%
  collect()


house_prices3$trading_ym <- as.Date(house_prices3$trading_ym)

house_prices3$area <- as.factor(house_prices3$area)


par(mfrow=c(4,3))
for (a in levels(house_prices3$area)){
    df <- house_prices3[house_prices3$area == a, ]
    plot(mean_price[order(df$trading_ym)] ~      trading_ym[order(df$trading_ym)], data = df, type='l', main = a)
}  


```

## Spark SQL
```{r}
createOrReplaceTempView(lvr_data, "lvr_data")


lvr_sql <- sql("SELECT area, avg(total_price) as mean_price FROM lvr_data WHERE house_age < 30 group by area")

lvr_sql <- sql("SELECT area, trading_ym, avg(total_price) as mean_price FROM lvr_data WHERE house_age < 30 group by area, trading_ym")

head(lvr_sql)

```


## Machine Learning With SparkR
```{r}
#install.packages('lars')
library(lars)
data("diabetes")
View(diabetes)

dim(diabetes$x)
diabetes$y

lm(y ~ x, data = diabetes)

diabetes_all <- data.frame(cbind(diabetes$x, y = diabetes$y))
View(diabetes_all)
outcome_name <- 'y'
diabetes_all$sex <- as.numeric(as.factor(diabetes_all$sex ))
str(diabetes_all)


set.seed(1234)
splitIndex <- base::sample(nrow(diabetes_all), floor(0.75*nrow(diabetes_all)))
#splitIndex
train_diabetes <- diabetes_all[ splitIndex,]
test_diabetes <- diabetes_all[-splitIndex,]
dim(train_diabetes)
dim(test_diabetes)


train_diabetes_sp <- as.DataFrame(train_diabetes)
test_diabetes_sp  <- as.DataFrame(test_diabetes)


model <- SparkR::glm(y~age+sex+bmi+map+tc+ldl+hdl+tch+ltg+glu,
data=train_diabetes_sp, family='gaussian')
SparkR::summary(model)


model2 <- glm(y~age+sex+bmi+map+tc+ldl+hdl+tch+ltg+glu,
data=train_diabetes, family='gaussian')

summary(model2)



predictions <- predict(model, newData = test_diabetes_sp)
names(predictions)

predictions_details <- select(predictions, predictions$label,
predictions$prediction)

collect(predictions_details)

predictions_details <- collect(predictions_details)

mse <- mean(predictions_details$label - predictions_details$prediction)
mse

```

## House Price Prediction
```{r}
#str(lvr_prices)
#plot(log(total_price) ~ log(building_sqmeter), data = lvr_prices)
fit <- glm(total_price ~ building_sqmeter, data = lvr_data, family = 'gaussian')
pred <- summary(fit)
pred

222370/0.3025
```

## Logistic Regression
```{r}
data(iris)
iris.data <-  iris[1:100,]
iris.data$Species <-  factor(iris.data$Species, labels = c(0,1))

fit <- glm(Species ~., data = iris.data, family=binomial(logit))
predict(fit, iris.data)


iris.data.sp <- as.DataFrame(iris.data)
fit3 <- SparkR::glm(Species ~., data = iris.data.sp, family=binomial(logit))
write.ml(fit3, '/tmp/model2')

model <- read.ml('/tmp/model2')



```
## sample save model
```{r}
irisDF <- suppressWarnings(createDataFrame(iris))
# Fit a generalized linear model of family "gaussian" with spark.glm
gaussianDF <- irisDF
gaussianTestDF <- irisDF
gaussianGLM <- spark.glm(gaussianDF, Sepal_Length ~ Sepal_Width + Species, family = "gaussian")

# Save and then load a fitted MLlib model
modelPath <- tempfile(pattern = "ml", fileext = ".tmp")
write.ml(gaussianGLM, modelPath)
gaussianGLM2 <- read.ml(modelPath)

# Check model summary
summary(gaussianGLM2)

# Check model prediction
gaussianPredictions <- predict(gaussianGLM2, gaussianTestDF)
showDF(gaussianPredictions)

unlink(modelPath)
```





## DPLYR
```{r}
#install.packages('dplyr')
library(dplyr)

head(filter(select(lvr_prices, total_price, area, floor), area == '中山區' ))

lvr_prices %>% 
  select(total_price, area, floor) %>% 
  filter(area == '中山區') %>% 
  head()



```

